{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /Users/ryanmangeno/Documents/dev/ai-env/lib/python3.13/site-packages (2.7.1)\n",
            "Requirement already satisfied: filelock in /Users/ryanmangeno/Documents/dev/ai-env/lib/python3.13/site-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/ryanmangeno/Documents/dev/ai-env/lib/python3.13/site-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: setuptools in /Users/ryanmangeno/Documents/dev/ai-env/lib/python3.13/site-packages (from torch) (80.9.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /Users/ryanmangeno/Documents/dev/ai-env/lib/python3.13/site-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx in /Users/ryanmangeno/Documents/dev/ai-env/lib/python3.13/site-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /Users/ryanmangeno/Documents/dev/ai-env/lib/python3.13/site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /Users/ryanmangeno/Documents/dev/ai-env/lib/python3.13/site-packages (from torch) (2025.5.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/ryanmangeno/Documents/dev/ai-env/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ryanmangeno/Documents/dev/ai-env/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
            "Collecting matplotlib\n",
            "  Using cached matplotlib-3.10.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (11 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib)\n",
            "  Using cached contourpy-1.3.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.5 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib)\n",
            "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib)\n",
            "  Using cached fonttools-4.58.4-cp313-cp313-macosx_10_13_universal2.whl.metadata (106 kB)\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
            "  Using cached kiwisolver-1.4.8-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.2 kB)\n",
            "Collecting numpy>=1.23 (from matplotlib)\n",
            "  Using cached numpy-2.3.0-cp313-cp313-macosx_14_0_arm64.whl.metadata (62 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/ryanmangeno/Documents/dev/ai-env/lib/python3.13/site-packages (from matplotlib) (25.0)\n",
            "Collecting pillow>=8 (from matplotlib)\n",
            "  Using cached pillow-11.2.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (8.9 kB)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
            "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/ryanmangeno/Documents/dev/ai-env/lib/python3.13/site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /Users/ryanmangeno/Documents/dev/ai-env/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Using cached matplotlib-3.10.3-cp313-cp313-macosx_11_0_arm64.whl (8.1 MB)\n",
            "Using cached contourpy-1.3.2-cp313-cp313-macosx_11_0_arm64.whl (255 kB)\n",
            "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Using cached fonttools-4.58.4-cp313-cp313-macosx_10_13_universal2.whl (2.7 MB)\n",
            "Using cached kiwisolver-1.4.8-cp313-cp313-macosx_11_0_arm64.whl (65 kB)\n",
            "Using cached numpy-2.3.0-cp313-cp313-macosx_14_0_arm64.whl (5.1 MB)\n",
            "Using cached pillow-11.2.1-cp313-cp313-macosx_11_0_arm64.whl (3.0 MB)\n",
            "Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
            "Installing collected packages: pyparsing, pillow, numpy, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8/8\u001b[0m [matplotlib]8\u001b[0m [matplotlib]\n",
            "\u001b[1A\u001b[2KSuccessfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.58.4 kiwisolver-1.4.8 matplotlib-3.10.3 numpy-2.3.0 pillow-11.2.1 pyparsing-3.2.3\n",
            "Requirement already satisfied: numpy in /Users/ryanmangeno/Documents/dev/ai-env/lib/python3.13/site-packages (2.3.0)\n",
            "Collecting kagglehub\n",
            "  Downloading kagglehub-0.3.12-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: packaging in /Users/ryanmangeno/Documents/dev/ai-env/lib/python3.13/site-packages (from kagglehub) (25.0)\n",
            "Collecting pyyaml (from kagglehub)\n",
            "  Using cached PyYAML-6.0.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
            "Collecting requests (from kagglehub)\n",
            "  Using cached requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting tqdm (from kagglehub)\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests->kagglehub)\n",
            "  Using cached charset_normalizer-3.4.2-cp313-cp313-macosx_10_13_universal2.whl.metadata (35 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->kagglehub)\n",
            "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->kagglehub)\n",
            "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->kagglehub)\n",
            "  Using cached certifi-2025.6.15-py3-none-any.whl.metadata (2.4 kB)\n",
            "Downloading kagglehub-0.3.12-py3-none-any.whl (67 kB)\n",
            "Using cached PyYAML-6.0.2-cp313-cp313-macosx_11_0_arm64.whl (171 kB)\n",
            "Using cached requests-2.32.4-py3-none-any.whl (64 kB)\n",
            "Using cached charset_normalizer-3.4.2-cp313-cp313-macosx_10_13_universal2.whl (199 kB)\n",
            "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
            "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
            "Using cached certifi-2025.6.15-py3-none-any.whl (157 kB)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Installing collected packages: urllib3, tqdm, pyyaml, idna, charset_normalizer, certifi, requests, kagglehub\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8/8\u001b[0m [kagglehub]/8\u001b[0m [requests]\n",
            "\u001b[1A\u001b[2KSuccessfully installed certifi-2025.6.15 charset_normalizer-3.4.2 idna-3.10 kagglehub-0.3.12 pyyaml-6.0.2 requests-2.32.4 tqdm-4.67.1 urllib3-2.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch\n",
        "!pip install matplotlib\n",
        "!pip install numpy\n",
        "!pip install kagglehub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "5ZuaZUp5oJh8"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import kagglehub\n",
        "import torch\n",
        "import os\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azgDdIu0lwVv"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "g44jFQs2qCGl"
      },
      "outputs": [],
      "source": [
        "def download_dataset() -> str:\n",
        "    path = kagglehub.dataset_download(\"rishitjakharia/names-txt\")\n",
        "    return path # for easier access later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MA9H16s-qPXT",
        "outputId": "c80c0fdd-a5c0-4e6d-c8a6-10545316963a"
      },
      "outputs": [],
      "source": [
        "dataset_path = download_dataset() + \"/names.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "VYqGvxdiqWwr"
      },
      "outputs": [],
      "source": [
        "words = open(dataset_path, 'r').read().splitlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "K2-SWXb-qnq7"
      },
      "outputs": [],
      "source": [
        "def make_int_char_maps() -> tuple[dict, dict]:\n",
        "  chars = sorted(list(set(''.join(words))))\n",
        "  ctoi = {c: i + 1 for i, c in enumerate(chars)}\n",
        "  ctoi['.'] = 0\n",
        "  itoc = {i: c for c, i in ctoi.items()}\n",
        "  return ctoi, itoc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "RdXYrtwBq5sT"
      },
      "outputs": [],
      "source": [
        "ctoi, itoc = make_int_char_maps()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niQbCUjPrAuD",
        "outputId": "6fd5a885-ce39-4d1a-823e-c0a76e440638"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
          ]
        }
      ],
      "source": [
        "print(itoc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4t-Rs9ExvDw2",
        "outputId": "b51c2c4b-6ef4-437f-cc30-7311e8b1e209"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, '.': 0}\n"
          ]
        }
      ],
      "source": [
        "print(ctoi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bpbdik5_ne80",
        "outputId": "93432146-53fd-4ba9-b711-792cf4885f5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "27\n"
          ]
        }
      ],
      "source": [
        "vocab_size = len(ctoi)\n",
        "print(vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {
        "id": "jJqoPknQvJ2N"
      },
      "outputs": [],
      "source": [
        "block_size = 7\n",
        "def build_dataset(inp_words) -> tuple[torch.tensor, torch.tensor]:\n",
        "  X, Y = [], []\n",
        "  for w in words:\n",
        "      # pad with '.' for start, append '.' for end\n",
        "      padded = '.' * block_size + w + '.'\n",
        "      for i in range(len(w) + 1):  # +1 to include the end token\n",
        "          context = padded[i:i+block_size]\n",
        "          target = padded[i+block_size]\n",
        "          X.append([ctoi[c] for c in context])\n",
        "          Y.append(ctoi[target])\n",
        "  X = torch.tensor(X, dtype=torch.long)\n",
        "  Y = torch.tensor(Y, dtype=torch.long)\n",
        "  return X, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {
        "id": "wjgYr1ucOsG3"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "random.seed(42)\n",
        "\n",
        "random.shuffle(words)\n",
        "n1 = int(0.8 * len(words))\n",
        "n2 = int(0.9 * len(words))\n",
        "\n",
        "Xtr, Ytr = build_dataset(words[:n1])\n",
        "Xdev, Ydev = build_dataset(words[n1:n2])\n",
        "Xte, Yte = build_dataset(words[n2:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([228146, 7]), torch.Size([228146]))"
            ]
          },
          "execution_count": 208,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Xtr.shape, Ytr.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YCp0YnriePg",
        "outputId": "e37210b7-1fd4-4680-d129-daacaaa929cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "....... --> n\n",
            "......n --> a\n",
            ".....na --> s\n",
            "....nas --> i\n",
            "...nasi --> a\n",
            "..nasia --> h\n",
            ".nasiah --> .\n",
            "....... --> g\n",
            "......g --> i\n",
            ".....gi --> l\n",
            "....gil --> a\n",
            "...gila --> n\n",
            "..gilan --> a\n",
            ".gilana --> .\n",
            "....... --> e\n",
            "......e --> v\n",
            ".....ev --> e\n",
            "....eve --> r\n",
            "...ever --> l\n",
            "..everl --> e\n",
            ".everle --> a\n",
            "everlea --> .\n",
            "....... --> k\n",
            "......k --> h\n",
            ".....kh --> y\n",
            "....khy --> r\n",
            "...khyr --> i\n",
            "..khyri --> e\n",
            ".khyrie --> .\n",
            "....... --> s\n"
          ]
        }
      ],
      "source": [
        "for x,y in zip(Xtr[:30], Ytr[:30]):\n",
        "  print(''.join(itoc[ix.item()] for ix in x), '-->', itoc[y.item()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_emb = 32 # dimensionality of the character vectors\n",
        "n_hidden = 150 # num hidden layer neurons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RNN_Model(nn.Module):\n",
        "    def __init__(self, vocab_size, n_emb, n_hidden):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, n_emb)\n",
        "        self.gru = nn.GRU(n_emb, n_hidden, num_layers=1, batch_first=True)\n",
        "        self.linear = nn.Linear(n_hidden, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch, seq)\n",
        "        x = self.embedding(x)                  # (batch, seq, n_emb)\n",
        "        output, h_n = self.gru(x)              # output: (batch, seq, n_hidden)\n",
        "        x = self.linear(output)                # (batch, seq, vocab_size)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 230,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num Params: 87741\n"
          ]
        }
      ],
      "source": [
        "model = RNN_Model(vocab_size, n_emb, n_hidden)\n",
        "\n",
        "# make the last layer less confident\n",
        "with torch.no_grad():\n",
        "    model.linear.weight.mul(0.1)\n",
        "\n",
        "params = model.parameters()\n",
        "print(f\"Num Params: {sum(p.nelement() for p in params)}\")\n",
        "for param in params:\n",
        "    param.requires_grad = True\n",
        "\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50_000, gamma=0.5) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 231,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RNN_Model(\n",
            "  (embedding): Embedding(27, 32)\n",
            "  (gru): GRU(32, 150, batch_first=True)\n",
            "  (linear): Linear(in_features=150, out_features=27, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 232,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RNN_Model(\n",
              "  (embedding): Embedding(27, 32)\n",
              "  (gru): GRU(32, 150, batch_first=True)\n",
              "  (linear): Linear(in_features=150, out_features=27, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 232,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lossi = []\n",
        "num_epochs = 100_000\n",
        "batch_size = 64\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10000/100000, -> 2.800567388534546\n",
            "20000/100000, -> 2.787832498550415\n",
            "30000/100000, -> 2.6847105026245117\n",
            "40000/100000, -> 2.6579535007476807\n",
            "50000/100000, -> 2.7418408393859863\n",
            "60000/100000, -> 2.696767807006836\n",
            "70000/100000, -> 2.6535120010375977\n",
            "80000/100000, -> 2.9976890087127686\n",
            "90000/100000, -> 3.0047433376312256\n",
            "100000/100000, -> 2.8140430450439453\n"
          ]
        }
      ],
      "source": [
        "for i in range(num_epochs):\n",
        "\n",
        "    ixs = torch.randint(Xtr.shape[0], (batch_size,))\n",
        "    Yb = Ytr[ixs]\n",
        "    Xb = Xtr[ixs]\n",
        "\n",
        "    logits = model.forward(Xb)\n",
        "    probs = logits.view(batch_size, -1)\n",
        "\n",
        "    loss = F.cross_entropy(probs, Yb)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "\n",
        "    extr_loss = loss.item()\n",
        "    lossi.append(extr_loss)\n",
        "\n",
        "\n",
        "    if (i+1) % 10_000 == 0:\n",
        "        print(f\"{i+1}/{num_epochs}, -> {extr_loss}\")\n",
        "\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x169875d10>]"
            ]
          },
          "execution_count": 236,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGgCAYAAAB45mdaAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAANpZJREFUeJzt3Ql8VPW99/FfMtmAkIUtQBII+yJGWVxA0V4BLfJQaKtPS7mClle9IO1Fe+1FvC6lFpOW1qf02iJS1D5Vmlu9hVqFSxENyMO+aQBlETABsrBmJdtkntfvz8w4CUlIIDlnJvN5+zommZwwZ84s5zu/8/v/J8TlcrkEAADAJqF2XTEAAIAijAAAAFsRRgAAgK0IIwAAwFaEEQAAYCvCCAAAsBVhBAAA2IowAgAAbEUYAQAAtiKMAACAwA0j6enpEhISIo8//niT1s/IyDDrT5069XquFgAAtCFh1/qHO3fulGXLlklqamqT1j9x4oQ8+eSTMnbs2GZfV01NjZw+fVo6duxowgwAAPB/+vF3xcXF0rNnTwkNDW3ZMFJSUiLTp0+X5cuXy89//vOrru90Os36CxculI8//lguXrzYrOvTIJKcnHwtmwoAAGyWk5MjSUlJLRtG5s6dK5MmTZLx48c3KYz87Gc/k27dusmsWbNMGLmaiooKs3h4PlhYb0xMTMy1bDIAALBYUVGRKSbomY3GNDuMaN/Hnj17zGmapti8ebOsWLFC9u3b1+TrSEtLM1WUujSIEEYAAAgsV2uxaFYDq1Ym5s2bJ2+99ZZERUVddX09T/TQQw+Z0zldunRp8vUsWLBACgsLvYteLwAAaJtCXJ5zIE2wevVq+eY3vykOh6NWP4gmHm1M0VMrvr/Tasjw4cNrXabNqErXP3TokPTr169JZZ7Y2FgTTKiMAAAQGJp6/G7WaZpx48ZJVlZWrcseeeQRGTx4sMyfP79W6FB6ed31n3nmGVMxWbJkCU2pAACgeWFEG1CGDRtW67IOHTpI586dvZfPmDFDEhMTTd+Hnsqpu35cXJz5WvdyAAAQnK55npGGZGdnNzqWGAAA4Jp7RuxCzwgAAIGnqcdvShgAAMBWhBEAAGArwggAALAVYQQAANiKMAIAAGxFGAEAAG1rnpFAsmLzcck5XybfvTVZBndnyDAAAHYI6srI+5+elje2nJDsc2V2bwoAAEErqMNImHumWGeN38/7BgBAmxXUYcQRGmK+VhNGAACwTVCHkTDH5TBCZQQAAPsEdRihMgIAgP2COoyEecKIs8buTQEAIGgFdRihMgIAgP2COoyEORhNAwCA3YI7jFAZAQDAdkEdRjynaZw19IwAAGCXoA4jVEYAALBfUIcRh2cGVidhBAAAuwR1GKEyAgCA/YI6jHw1tJeeEQAA7BLUYYTKCAAA9gvqMOLwfDYNPSMAANgmqMNIuLuBlcoIAAD2Ceow8tU8I4QRAADsEtRhhJ4RAADsF9RhxNszwmgaAABsE9RhhMoIAAD2C+ow4p2BlTACAIBtgjqMeCsjDO0FAMA2QR1GmIEVAAD7BXUYCfc2sFIZAQAgIMNIenq6hISEyOOPP97gOsuXL5exY8dKfHy8WcaPHy87duwQf+oZoYEVAIAADCM7d+6UZcuWSWpqaqPrZWZmyrRp0+Sjjz6SrVu3SnJystx7771y6tQp8ZeeESojAAAEWBgpKSmR6dOnm6qHVjsa89Zbb8ljjz0mN998swwePFj+8Ic/SE1NjWzYsEH8pmeEBlYAAAIrjMydO1cmTZpkTrk0V1lZmVRVVUmnTp0aXKeiokKKiopqLa2ByggAAPYLa+4fZGRkyJ49e8xpmmsxf/586dmzZ6NBJi0tTRYuXCitjdE0AAAEWGUkJydH5s2bZ069REVFXVPDq4aZVatWNfr3CxYskMLCQu+i19sawtyjaWhgBQAgQCoju3fvloKCAhkxYoT3MqfTKZs2bZKXX37ZnF5xOBz1/u2vfvUrE0Y++OCDqza9RkZGmsWy0TT0jAAAEBhhZNy4cZKVlVXrskceecQ0purpl4aCyC9/+UtZtGiRrFu3TkaNGiX+gp4RAAACLIx07NhRhg0bVuuyDh06SOfOnb2Xz5gxQxITE03fh/rFL34hzz33nKxcuVJSUlIkLy/PXB4dHW0W//igPHpGAABoMzOwZmdnS25urvfnpUuXSmVlpTzwwAPSo0cP76Knbezm6RmhMgIAQACNpqlvUrPGfj5x4oT4K2ZgBQDAfkH92TT0jAAAYL+gDiNfzTNCGAEAwC5BHUaojAAAYL+gDiOeykiVk9E0AADYJajDSJi7gZXKCAAA9gnuMMJ08AAA2C64wwg9IwAA2C6ow4jDJ4y4XAQSAADsENRhxNMzoqiOAABgj6AOIw53z4iibwQAAHsEdRjx9IwoKiMAANgjqMOIp2dEVTsJIwAA2CG4w0iI72kaJj4DAMAOQR1GQkNDxFMc4TQNAAD2COowosIcl3cBDawAANiDMMLEZwAA2Crow4iniZXKCAAA9gj6MPJVZYQGVgAA7BD0YcThnoWVyggAAPYI+jDiqYwwzwgAAPYI+jBCzwgAAPYK+jAS5v58GnpGAACwR9CHEW9lhNM0AADYIujDSLi7gZV5RgAAsEfQhxF6RgAAsFfQh5GvekYIIwAA2CHowwiVEQAA7BX0YYQZWAEAsFfQhxFPZaSK0TQAANgi6MNIGKNpAACwVdCHEXpGAAAI4DCSnp4uISEh8vjjjze63ttvvy2DBw+WqKgoufHGG2XNmjXiL8KZgRUAgMAMIzt37pRly5ZJampqo+tt2bJFpk2bJrNmzZK9e/fK1KlTzbJ//37xB1RGAAAIwDBSUlIi06dPl+XLl0t8fHyj6y5ZskS+/vWvy09+8hMZMmSIvPDCCzJixAh5+eWXxR/QMwIAQACGkblz58qkSZNk/PjxV11369atV6x33333mcsbUlFRIUVFRbWW1sJn0wAAYK+w5v5BRkaG7Nmzx5ymaYq8vDxJSEiodZn+rJc3JC0tTRYuXCjWzjNCGAEAwO8rIzk5OTJv3jx56623TDNqa1mwYIEUFhZ6F73e1kLPCAAAAVQZ2b17txQUFJieDw+n0ymbNm0yPSB6esXhcNT6m+7du0t+fn6ty/RnvbwhkZGRZrHys2mqnYymAQDA7ysj48aNk6ysLNm3b593GTVqlGlm1e/rBhE1evRo2bBhQ63L1q9fby73B1RGAAAIoMpIx44dZdiwYbUu69Chg3Tu3Nl7+YwZMyQxMdH0fSg9rXP33XfLr3/9a9P0qj0nu3btkldffVX8AaNpAABoYzOwZmdnS25urvfnMWPGyMqVK034uOmmm+Sdd96R1atXXxFq7OJpYKUyAgBAgIymqSszM7PRn9WDDz5oFn/kYAZWAABsFfSfTUNlBAAAewV9GHHQMwIAgK2CPoxQGQEAwF5BH0a+mg6enhEAAOwQ9GGEyggAAPYK+jDiqYzQMwIAgD2CPoyEOy7vAiojAADYI+jDiLcy4iSMAABgh6API/SMAABgr6API1/1jDCaBgAAOwR9GAlzTwdPZQQAAHsEfRhhBlYAAOwV9GHE2zNCAysAALYI+jDinYGVnhEAAGwR9GHEUxnhNA0AAPYgjDDpGQAAtiKMUBkBAMBWQR9GvuoZIYwAAGCHoA8jVEYAALBX0IcRRtMAAGCvoA8jYe5Jz5hnBAAAewR9GKFnBAAAewV9GPF8Ng09IwAA2CPow4i3MuKkZwQAADsEfRgJ54PyAACwVdCHEYf7NA09IwAA2CPowwjzjAAAYK+gDyO+o2lcLgIJAABWC/ow4qmMKIojAABYL+jDiKcyoqoYUQMAgOWCPox4ZmBV9I0AAGC9oA8jvpURRtQAAODnYWTp0qWSmpoqMTExZhk9erSsXbu20b/5zW9+I4MGDZJ27dpJcnKyPPHEE1JeXi7+2DNCZQQAAOuFNWflpKQkSU9PlwEDBpiRJ3/84x9lypQpsnfvXrnhhhuuWH/lypXy1FNPyWuvvSZjxoyRw4cPy8MPPywhISHy0ksviT8IDQ0RzSOaQ/jkXgAA/DyMTJ48udbPixYtMtWSbdu21RtGtmzZInfccYd873vfMz+npKTItGnTZPv27eJvfSOVzhoqIwAABFLPiNPplIyMDCktLTWna+qj1ZDdu3fLjh07zM/Hjh2TNWvWyP3339/ov11RUSFFRUW1Fms+n4YwAgCAX1dGVFZWlgkf2vcRHR0tq1atkqFDh9a7rlZEzp49K3feeac5rVNdXS2zZ8+Wp59+utHrSEtLk4ULF4pVmIUVAIAAqoxoM+q+ffvMqZY5c+bIzJkz5eDBg/Wum5mZKS+++KL8/ve/lz179shf//pXef/99+WFF15o9DoWLFgghYWF3iUnJ0es+XwaekYAALBaiOs650AfP3689OvXT5YtW3bF78aOHSu33367LF682HvZm2++KY8++qiUlJRIqM8cH43R0zSxsbEmmOgonpY26ufr5WxJpfzP42NlcPeW//cBAAhGRU08fl/3PCM1NTWmx6M+ZWVlVwQOh8NhvvrT58DQMwIAQID0jOjpk4kTJ0qvXr2kuLjYDN3VUzHr1q0zv58xY4YkJiaang/P6Bsdwjt8+HC57bbb5OjRo/Lss8+ayz2hxJ9mYaVnBAAAPw8jBQUFJnDk5uaasotOgKZBZMKECeb32dnZtSohzzzzjJlTRL+eOnVKunbtaoKIDgn2J2HenhHCCAAAAdczYoXW7hm559eZcuxMqfzlX0bLrX06tfi/DwBAMCqyqmekLfAM7WU0DQAA1iOMmAZWekYAALALYaRWZYQwAgCA1QgjDO0FAMBWhJFa08HTMwIAgNUII76VEU7TAABgOcKIiIQ7aGAFAMAuhBF6RgAAsBVhpFbPCGEEAACrEUboGQEAwFaEEZ/PpmE0DQAA1iOM+MzASmUEAADrEUZ8Z2ClgRUAAMsRRugZAQDAVoQRZmAFAMBWhBGfBlYqIwAAWI8wYiojzMAKAIBdCCP0jAAAYCvCCDOwAgBgK8IIn00DAICtCCO+84wwmgYAAMsRRpiBFQAAWxFGfD+bhtM0AABYjjDCaBoAAGxFGGEGVgAAbEUYqdXASmUEAACrEUb0NI2DGVgBALALYYTKCAAAtiKM+DSwUhkBAMB6hBGfykiVkwZWAACsRhihMgIAQOCEkaVLl0pqaqrExMSYZfTo0bJ27dpG/+bixYsyd+5c6dGjh0RGRsrAgQNlzZo14k/CmIEVAADbhDVn5aSkJElPT5cBAwaIy+WSP/7xjzJlyhTZu3ev3HDDDVesX1lZKRMmTJBu3brJO++8I4mJifLll19KXFyc+OUMrIQRAAD8O4xMnjy51s+LFi0y1ZJt27bVG0Zee+01OX/+vGzZskXCw8PNZSkpKeJvGE0DAEAA9ow4nU7JyMiQ0tJSc7qmPu+++675nZ6mSUhIkGHDhsmLL75o/rYxFRUVUlRUVGuxpmeEBlYAAPy6MqKysrJMwCgvL5fo6GhZtWqVDB06tN51jx07Jh9++KFMnz7d9IkcPXpUHnvsMamqqpLnn3++wetIS0uThQsXiuU9I3xQHgAAlgtxafNHM2gfSHZ2thQWFpo+kD/84Q+ycePGegOJNqtqaDl+/Lg4HA5z2UsvvSSLFy+W3NzcRisjunhoZSQ5OdlcpzbOtrStX5yTacu3yYBu0bL+x3e3+L8PAEAwKioqktjY2Ksev5tdGYmIiJD+/fub70eOHCk7d+6UJUuWyLJly65YV0fQaK+IJ4ioIUOGSF5engk1+m/VR0fd6GJ1Ays9IwAABOA8IzU1NbWqGL7uuOMOc2pG1/E4fPiwCSkNBRE7eHpGqukZAQDAv8PIggULZNOmTXLixAnTO6I/Z2Zmmp4QNWPGDHOZx5w5c8xomnnz5pkQ8v7775sGVm1o9cfRNE56RgAAsFyzTtMUFBSYwKH9HnoOSCdAW7dunZlLRGkvSai7GVRpn4f+/oknnjDr6jwjGkzmz58v/uSryghhBAAAvw4jK1asaPT3WiWpS0fe6Dwk/izccTlAMekZAADW47NpqIwAAGArwohvzwhhBAAAyxFGGE0DAICtCCM+M7BSGQEAwHqEEZ/KSJXTZT6NGAAAWIcw4tMzoiiOAABgLcKIVkbc08Er+kYAALAWYaROZYS+EQAArEUY8WlgVcw1AgCAtQgjdSsjfD4NAACWIozoTggNkRB3HqEyAgCAtQgjbszCCgCAPQgjV8w1wmgaAACsRBhxYxZWAADsQRhx45N7AQCwB2HEjZ4RAADsQRhxC3PPwsoMrAAAWIsw4kbPCAAA9iCMuNEzAgCAPQgjbvSMAABgD8JI3coI08EDAGApwsgVp2loYAUAwEqEkStG01AZAQDASoQRN4dnNA2naQAAsBRhpE4DK5URAACsRRhxYzQNAAD2IIy4MQMrAAD2IIzU7RmhMgIAgKUII270jAAAYA/CiBuTngEAYA/CyBUNrPSMAABgJcKIGx+UBwBAAISRpUuXSmpqqsTExJhl9OjRsnbt2ib9bUZGhoSEhMjUqVPFHzG0FwCAAAgjSUlJkp6eLrt375Zdu3bJPffcI1OmTJEDBw40+ncnTpyQJ598UsaOHSv+KsxxeVdQGQEAwI/DyOTJk+X++++XAQMGyMCBA2XRokUSHR0t27Zta/BvnE6nTJ8+XRYuXCh9+/YVf0VlBACAAOsZ0ZChp15KS0vN6ZqG/OxnP5Nu3brJrFmzmvxvV1RUSFFRUa2ltTGaBgAAe4Q19w+ysrJM+CgvLzdVkVWrVsnQoUPrXXfz5s2yYsUK2bdvX7OuIy0tzVRSrMRoGgAAAqQyMmjQIBMutm/fLnPmzJGZM2fKwYMHr1ivuLhYHnroIVm+fLl06dKlWdexYMECKSws9C45OTli1Qys9IwAAODnlZGIiAjp37+/+X7kyJGyc+dOWbJkiSxbtqzWel988YVpXNU+E48ad9UhLCxMDh06JP369av3OiIjI81iz2fTEEYAAPDrMFKXBgzt8ahr8ODB5pSOr2eeecZUTDS8JCcniz+hZwQAgAAII3r6ZOLEidKrVy8TKlauXCmZmZmybt068/sZM2ZIYmKi6fmIioqSYcOG1fr7uLg487Xu5f6AnhEAAAIgjBQUFJjAkZubK7GxsWYCNA0iEyZMML/Pzs6WUHfvRaBhBlYAAAIgjOjImMZolaQxb7zxhvircPekZ8wzAgCAtQKzjNEKqIwAAGAPwogbM7ACAGAPwogblREAAOxBGKlTGal2MpoGAAArEUbcmIEVAAB7EEbc6BkBAMAehBE3ekYAALAHYaTOZ9MwAysAANYijLiFeXpG+GwaAAAsRRipc5qGnhEAAKxFGKk7tJcwAgCApQgjbg5vzwhhBAAAKxFG6lRGqpj0DAAASxFG3OgZAQDAHoSROqNpCCMAAFiLMOLGpGcAANiDMOIWTgMrAAC2IIxcURmhgRUAACsRRtzoGQEAwB6EETd6RgAAsAdhpO4MrHw2DQAAliKMuNEzAgCAPQgjbmGMpgEAwBaEETd6RgAAsAdhpM5oGpdLpIZAAgCAZQgjdU7TKKojAABYhzBSZzSNom8EAADrEEbq9IwoRtQAAGAdwkidnhFFZQQAAOsQRtx8CiNSxcRnAABYhjDiFhIS4u0boTICAIB1CCM+mIUVAAA/DyNLly6V1NRUiYmJMcvo0aNl7dq1Da6/fPlyGTt2rMTHx5tl/PjxsmPHDvFXVEYAAPDzMJKUlCTp6emye/du2bVrl9xzzz0yZcoUOXDgQL3rZ2ZmyrRp0+Sjjz6SrVu3SnJystx7771y6tQp8Udhjsu7g3lGAACwTojLpXOOXrtOnTrJ4sWLZdasWVdd1+l0mgrJyy+/LDNmzGhwvYqKCrN4FBUVmSBTWFhoKjKtZeQL6+VcaaX844m7ZGBCx1a7HgAAgkFRUZHExsZe9fh9zT0jGiwyMjKktLTUnK5pirKyMqmqqjIBpjFpaWlm4z2LBhFLe0YYTQMAgGWaHUaysrIkOjpaIiMjZfbs2bJq1SoZOnRok/52/vz50rNnT9M70pgFCxaYFOVZcnJyxAr0jAAAYL2w5v7BoEGDZN++fSYkvPPOOzJz5kzZuHHjVQOJ9ppoJUX7SKKiohpdV4OOLlZzuD+fporRNAAA+G8YiYiIkP79+5vvR44cKTt37pQlS5bIsmXLGvybX/3qVyaMfPDBB2Y0jr/PwkplBAAAPw4jddXU1NRqNq3rl7/8pSxatEjWrVsno0aNEn9GzwgAAH4eRrSXY+LEidKrVy8pLi6WlStXmtMuGjSUjpBJTEw0DajqF7/4hTz33HNmvZSUFMnLyzOXa8+JLv6GnhEAAPw8jBQUFJjAkZuba0a56CkXDSITJkwwv8/OzpZQnw+c00nSKisr5YEHHqj17zz//PPy05/+VPwNM7ACAODnYWTFihWN/l6rJL5OnDghgcQz6RmVEQAArMNn09RzmoYZWAEAsA5hpJ7TNFRGAACwDmHEB5URAACsRxipd2gvDawAAFiFMOKDyggAANYjjPhwMAMrAACWI4z4oDICAID1CCP1fFCek54RAAAsQxjxEU5lBAAAyxFGfNAzAgCA9QgjPugZAQDAeoSRenpGqp2EEQAArEIYqacy4uRTewEAsAxhpL4ZWDlNAwCAZQgj9VZGCCMAAFiFMFLPaBoqIwAAWIcw4iPcM+kZYQQAAMsQRurtGaGBFQAAqxBGfNAzAgCA9Qgj9fWMMM8IAACWIYz4YAZWAACsRxjxwTwjAABYjzDiI8w7moYGVgAArEIYqa8yQs8IAACWIYz4YDQNAADWI4z4CGMGVgAALEcYqbdnhDACAIBVCCM+mIEVAADrEUbqm2eEBlYAACxDGPHBp/YCAGA9wogPRtMAAODnYWTp0qWSmpoqMTExZhk9erSsXbu20b95++23ZfDgwRIVFSU33nijrFmzRvwVM7ACAODnYSQpKUnS09Nl9+7dsmvXLrnnnntkypQpcuDAgXrX37Jli0ybNk1mzZole/fulalTp5pl//794t+VERpYAQCwSojL5bquMkCnTp1k8eLFJnDU9Z3vfEdKS0vlvffe8152++23y8033yyvvPJKk6+jqKhIYmNjpbCw0FRkWsuO4+flfy/bKn27dpAP/+1rrXY9AAAEg6ImHr+vuWfE6XRKRkaGCRt6uqY+W7dulfHjx9e67L777jOXN6aiosLcAN/FynlGKqqojAAAYJVmh5GsrCyJjo6WyMhImT17tqxatUqGDh1a77p5eXmSkJBQ6zL9WS9vTFpamklSniU5OVmskBTfznzNLbwk5VVOS64TAIBg1+wwMmjQINm3b59s375d5syZIzNnzpSDBw+26EYtWLDAlHQ8S05Ojliha3SkxLcPF+1fPVpQYsl1AgAQ7JodRiIiIqR///4ycuRIU8G46aabZMmSJfWu2717d8nPz691mf6slzdGqy6eETuexQohISEyMKGj+f5wfrEl1wkAQLC77nlGampqTI9HfbSXZMOGDbUuW79+fYM9Jv5gUPfLYeQQYQQAAEuENff0ycSJE6VXr15SXFwsK1eulMzMTFm3bp35/YwZMyQxMdFUTNS8efPk7rvvll//+tcyadIk0/CqQ4JfffVV8VeeysihPMIIAAB+F0YKCgpM4MjNzTWNpToBmgaRCRMmmN9nZ2dLqHtKdTVmzBgTWJ555hl5+umnZcCAAbJ69WoZNmyY+KvB7srIYcIIAACBMc+IFayaZ0QVXqqSmxb+w3z/6U/vlZio8Fa9PgAA2qpWn2ekrYptFy49YqPM90foGwEAoNURRhrtG2F4LwAArY0w0tiImjxrZn4FACCYEUbqMchTGeE0DQAArY4w0mhlpFgCoL8XAICARhipR/9u0RISInKhrErOllTavTkAALRphJF6RIU7JKVzB/M908IDANC6CCMNGJgQbb4yEysAAK2LMNKAQd0vT85CGAEAoHURRhrAiBoAAKxBGGnAoO7R3llYa2oYUQMAQGshjDSgd+cOEuEIldJKp5y6eMnuzQEAoM0ijDQg3BEqfbsyogYAgNZGGGnK5GeEEQAAWg1hpIkzsQIAgNZBGGnKiBrCCAAArYYw0oiB7jBy7EypVDlr7N4cAADaJMJIIxLj2kmHCIdUOmvky3Oldm8OAABtEmGkEaGhITLAXR05mMupGgAAWgNh5CpuSYk3X9/elWP3pgAA0CYRRq5ixugUcYSGyMdHzsr+U4V2bw4AAG0OYeQqkju1l8mpPcz3r2z8wu7NAQCgzSGMNMG/3N3PfF2TlUsjKwAALYww0gRDesTI1wZ1Ff28vFc3HbN7cwAAaFMII000210deXv3STlTXGH35gAA0GYQRprotj6dZHivOKmsrpE3thy3e3MAAGgzCCNNFBIS4q2O/Gnrl1JcXmX3JgEA0CYQRpphwpAE6de1gxSVV8ufd2TbvTkAALQJhJFmzsj6L3ddro4s23hMTl28ZPcmAQAQ8AgjzTR1eKIM7t5RzpVWyiOv75DCS5yuAQDgehBGmikiLFRee/gWSYiJlMP5JTL7T7ulotpp92YBABCwCCPXoGdcO3n94VslOjJMth47J/Pf+VRcLpfdmwUAQNsPI2lpaXLLLbdIx44dpVu3bjJ16lQ5dOjQVf/uN7/5jQwaNEjatWsnycnJ8sQTT0h5ebkEsqE9Y+T300dIWGiIrN53Wn71j6vvBwAAcJ1hZOPGjTJ37lzZtm2brF+/XqqqquTee++V0tKGp0hfuXKlPPXUU/L888/LZ599JitWrJD/+q//kqeffloC3V0Du8qL37rRfP+7j76Qby/dIks+OCJ7sy+IU6drBQAAVxXiuo7zC2fOnDEVEg0pd911V73r/PCHPzQhZMOGDd7L/u3f/k22b98umzdvbtL1FBUVSWxsrBQWFkpMTIz4m999dFQWr6tdGYmJCpO7B3WTb9zUU+4a2EUiwxy2bR8AAHZo6vE77HquRP9x1alTpwbXGTNmjLz55puyY8cOufXWW+XYsWOyZs0aeeihhxr8m4qKCrP43hh/Nvef+suUm3vKx0fOyqbDZ2Tz0bNmLpK/f3LaLBpM7r+xhwkmI1PiCSYAALREZaSmpka+8Y1vyMWLF69a4fjtb38rTz75pGnyrK6ultmzZ8vSpUsbXP+nP/2pLFy48IrL/bUyUle1s0Y+OXlR1mTlmTBS4PNZNtpj0r9btAztEWP6TgZ3j5G+XTtI95goM48JAADBVhm55jAyZ84cWbt2rQkiSUlJDa6XmZkp3/3ud+XnP/+53HbbbXL06FGZN2+e/OAHP5Bnn322yZURbXwNlDDiS3tHth8/J+/uOy3/OJgv50sr612vXbhDUrp0kL5dOogjNETKq5xSXl1jvkY4QiU1KVZG9IqXEb3jpVOHCMtvBwAAfhVGtA/kb3/7m2zatEn69OnT6Lpjx46V22+/XRYvXuy9TE/bPProo1JSUiKhoaEB3zPSVLqr84rK5cCpIjmYWyQHThfKkYISyT5XJtXNaHjt06WDJHdqLx2jwqRjZJj52jk6Uu4Z3E0GJnRs1dsAAICtPSN6MP3Rj34kq1atMhWPqwURVVZWdkXgcDgu90wE29wc+mF7PWLbmWX80ATv5VXOGsk5XybHz5bKiXNl5rKo8FDTW6Jfi8urzQidPdkX5WhBiVlPl7rS135uZoedfFNPmZzaUzpHR8jh/GKzfJ5XLPlF5TK6XxeZnNpD4to3rbqi21VaWS2DEjqa7QcAoKU1qzLy2GOPmaG6WhXReUM8NPXoHCJqxowZkpiYaOYk8fR/vPTSS/Lqq696T9PoKZ6RI0eaIb5N0VYqIy3hYlmlfHKyUM4UV0hJeZUJKiUV1SakbDpyRqqcV7879bTPuCHd5NsjkszwZJ1Vtm4AWZOVK+9n5cqnJy83KesHBD44Klm+NSJRunWMapXbdqnSKZ/lFUnX6EgzsZyermotWo3KPFwgoSEh0rtze+nVqb0kxrWTMAfzAF6vmhqXOF0uCWdfepVWVJtTsfSFIdgUtcZpmobeGb/++uvy8MMPm++/9rWvSUpKirzxxhvmZ21YXbRokfzpT3+SU6dOSdeuXWXy5Mnmsri4uBa9McFOg8q6A3ny7ienZesX50TP/HSJjjTVkkHdO0pcu3ATMLRK4ivafaonJirc/Hwo/6vf62unHlQqqmvMzxoQvjawq+lv0X4YffjogUevy3xfc/n7GpfL/HtdO0aacNGlY4R0jY6ShNhI6dIh0vuirD0xmYfOyHufnpYNnxXIpSqnNzAld2onKZ07mIbfG5NiJTUxzlymj0NtEv70VKFsOXpWtnxxTvIKy6VDZJh0iHSY26NLQmyUJMW3l+T4duarTtv/jwP5Zh/V3Qee26aNxO0jHNIuwiFRWpmKcEj/rtHy9WHdZWTv+FoBSQ8w6w/mm33qCAmR79yaLHcP6HrFAUcrUqv2npJTFy6Z0KP7rk+X9uZU2/WOrNL99+W5MnMdF8oqTU/ShbIquVRZLf26RsuwxFhz3zclGOjnLOl+jGkXJrHtws3Bs7FqmN7fm46clVcyvzAfGllWWS1llU6z6C7wXP8NPWPMV+2H0n6nthL4dH/9ZWeOfHSowJwenTA0QW7t08m7r4vKq2TNp7nyzu6TsuvLCybsapjXNwH6GPAX+rz4+PBZ2XbsnNyQGGNG/tk94k+3KfdiufcU9LXQirMOIHh10zE5drZUvjU80Yx81OddXfrmTk+dD0yINpXr1lZZXSPhjhBLq80ul8sMpviioEROXrwkQ7rr8zKm1beh1RtYrUQYubZgosGgvifywdNF8t97Tsrf9p2SsyVXNtTqgeT2vp1lUmoPue+G7hIZFirvf5orf9mVY04VXS8dUdRNQ0pMlBzNL5bSyq8+20cPViXl1VLpvBx+6oprH24Ocofyik1F6FppqLg1pZMJHl+eL5Ps82XmBaIxGqzuuyHBNBJrgNIg4glPvv08D93e2wz13nnivPxl10nJPFRgAlpd+hqg+0Ff/HrGRUn3mHYmbA3pEWMWDQQeGr6+OFMq+08Vyme5RfLFmRLzc86FMrnaM1iD3eAeHWV4cpy5X2/r29nbBK0v2BsPnZG/7j0pHxwsqLXf9cVSt0FD2P9K7Wl6kjTwqU9PXjSnBTUINofe5s4dIkxI7hYTZUaVaXP2jYmxkhR/OWjqgSjn/CX58lyp5BaWS3z7COkeG2X2kQZbT5jRbdf9b5q9Ky9/r4uGIr0vdb+49D/3/tEgqI+d+qoTGiw/ybkoF+t88KVWzvR+1+vWiqA+bo6dKZE3tpwwIUODly89eH5tUDfzHNLQW15V/2Pq8j7tYUbTadVRr+NqBwWtOOn9rdVQ3/1Z7XSZ/aSB8LR70eesBsDUpDgTBj33m+ffKamslt0nLsh7n+bKPw7m1fo39b6Zflsvs+h9pK8lGlR0yoLdX16UnrFR5jSzVlfrVkn1384tujy7tr750edXfbdLH896YNTnnS457q8nL1ySkxfKzO/0ftPH4MNjUuRH4wZ43yxdjb4uZOzIltc2H5fTheVXvPZohfeH9/SXqLBQ+Z8DefLeJ7lmkIHnOaq3TwcK6PO8X7do6RDhuPxGJ+Lym52YduFNCve63/Q5qs9VfSzrbdPbmXPhkgk/WpHWzzjTN0AJMVEmJI3u29kE2qjw2mFQD9P6nPg8r8jcPn286utmWUW1dOkYKWP6dTaPbd99rc8jfVP64ecFppp+rKBEiuu8ZvbQ+3JIggnS+tpQt0reEggjuCp94dB30zonSnF5lRRdqjYv5jcnx5kXx/ocLSiWtVl55omgz0etCOgTQF+09Wf9Xl+wQ9zvDPVJZ5aSCskvqpCzJZdfZHzpO0YNPpNu7GEOTPqioC+o+o7/+LlSOZRXJFkn9SBcXOtgqcFEn7z6ROzfraM5KBW7n6h6e05fLPe+uOmLgFZwxg7oagLWuMHdJN5nVJLuC30BzC285D3AXaqsMf+WvhCv/yy/1gu2h57imXJTT7M/NKzVt466JSVeRvbuZLblxLlSOXG27KphSg/OWtXSaoe+a2vowKYHQN2HGjD0NnVqH2FeLPWFK+tUYb3bpP+uBp6Pj5ypFUh1Thy9LfXNIKz9SxpI9N7VapAn6MwY3Vsm3tjdvGC3Dw+T9pEOc4DU0KThaf/pQtl/qsjs28b6tOPb68ErTE4XXmowYOlBXtfR+6c5Td8eGq5G9IqTUSmdzP7dl3NRdp24YPbv1WZN1se1hiFtQvfQXqoHRyXJkfwS2fB5/hXhXqt6D4xMkvuH9ZB9Jy/Kf+8+afZ53avSRnQd4q+nJz3VRP2q16mPe92H+ibiWgK4Hp96d2pvHv/6HNfnRt3r1wPinQO6mG3T56nSIGCCf35xg/eHvlYM7xVnqhiXe95KvVVUz+NDn6fRUWFSUVVjgqI+vq4W/JUGKs+/1SU6Qn5y3yB5YGSyeQxoZfODg/nywecFciS/2FRiPdVZfVx4tleD1SN3pJjtfGXjF2YuKM9t0/V973N9I6CvGU2ZPVsrr/pY0tumgUt5rrOqxiUnz5eZT3a/FpFhoeYNw10Dupjbvzf7ouzLuVDvG0dfGmzG9Otiwqe+EdLbWjcs677TUK7h/pOcwlpvpvQx+NvvDZd/GtRNWhJhBH5J3xFpMNHTAfqip0+Km5Jim1Qq1BcwbcbV/hjPXC1NPQevD3N9pF/rOXu97v/3xVlZm5UrB04XmXcvU25OrLXtGlz0dMwft5wwo6S06vHtkUny4Mgk6ds1+ort0Rery+9kyyWv8JJ5d6vlZD2Ia4iqS9+h3dAz1sxPMyAh2hwodNEX6ob2n16Phjo9pbXrxHkTrPTTpn3p3+tt0dMH+m/r3+iLmDltU1RuXvT1HbS+c/XQq/vmzYnyxISB9Za96+N0h19PQNXbqAdZDZoanHz7nfS29u6sB2d9Z15l9o1uS30HCr1L9ZSSnlrT0wv6VQ+C2jevwUl/rwdifdw0FOiUBjpdTJJ20+pLQVHFFdetYfb7d/YxQdiz7zXQauDY8Fm+ebxoNUnDdd37pqCoXFbvO2Xeter9rUG5qblK37lq2PSt+Ghg0XfWifGXt1/f2WsA1ftcw6Duu/po2Jk4rLtpeB/ZK948N/T2/s/+PFP52f3lBe+6Wr25s38XubVPZ1MZ+uCzfPNuuz5afdA3Jw1VN33X023Wg6M+hszX+PYmJOqi4Trz8Bl54b2DcuxMqTf8aSDTKlBj9JTgo3f1lanDE2tVGfQg/X/WH/ZW9LQi53kjpNtgKmQnL5oAoLdf950JUBWXK251D+5Xo5UHfY6m6GlZPWXsvo36uNYgoKdXzWO7sNxUezf5hMG6NEDpKVetFHaIuBz69euxsyWy88SFegOevgZpBeuO/l3MqUR98+Q5BaeB/v8dPWsqvB98VmDeKG6e/0/mlHZLIowANtGnlL7A6AvBtfZHFJZVmXfrWhXSaoeW3Pt07tAiDZD6oqOh5PPcYhnRO85Ui65WdtbbpCFMQ0nhpUp56PYUE1xaipaUD+eVmAOYvmDqqZy6B3ENA7rtesDQ6ogGkKiIUBM8mhJm9UCr1QU9yOiiFRg9GGmVZFTveFOVaIjnujU86rvtpgawpt52bajWkn5BcbkJP55qojZ16wFI7389v68HtuY2Buu/eTS/RCLDHRLb7nJvmJ5qqHsqoC4NMhpk9ZSSvmmoSw+k2uelIU+rCnqKUhcNRBqQ9MCtp70ulFaaAKH3l6cfS+8/rcI15fmhB9n/u/WE+dwvz2kGrdJpONJTDLf06WSqCRqAzBIqprLU2GNCK7wRDof06ty8+1EfB1pZ0r4sPQ2jt6+80mnC+WVaKb4cbHVf+J4eawqXy2XeyOhM3hpW9T7SytPwXvGm4tHQfabBYs+XF8ypNK0a6eNl/JBuMqxnbJNeMzRI6+ABfbPT0ggjAIA2Q8Og9q7pgV7f6Wuogf+z5LNpAACwglakZo5JsXsz0Eraxhg7AAAQsAgjAADAVoQRAABgK8IIAACwFWEEAADYijACAABsRRgBAAC2IowAAABbEUYAAICtCCMAAMBWhBEAAGArwggAALAVYQQAANgqID611+VyeT+KGAAABAbPcdtzHA/oMFJcXGy+Jicn270pAADgGo7jsbGxDf4+xHW1uOIHampq5PTp09KxY0cJCQlp0cSmAScnJ0diYmJa7N/FldjX1mFfW4v9bR32deDta40YGkR69uwpoaGhgV0Z0RuQlJTUav++7mge2NZgX1uHfW0t9rd12NeBta8bq4h40MAKAABsRRgBAAC2CuowEhkZKc8//7z5itbFvrYO+9pa7G/rsK/b7r4OiAZWAADQdgV1ZQQAANiPMAIAAGxFGAEAALYijAAAAFsRRgAAgK2COoz87ne/k5SUFImKipLbbrtNduzYYfcmBby0tDS55ZZbzNT93bp1k6lTp8qhQ4dqrVNeXi5z586Vzp07S3R0tHz729+W/Px827a5LUhPTzcflfD44497L2M/t6xTp07JP//zP5v92a5dO7nxxhtl165d3t/rwMTnnntOevToYX4/fvx4OXLkiK3bHIicTqc8++yz0qdPH7Mf+/XrJy+88EKtD1pjX1+bTZs2yeTJk83U7Pp6sXr16lq/b8p+PX/+vEyfPt3MyhoXFyezZs2SkpKSa9yi2lcelDIyMlwRERGu1157zXXgwAHXD37wA1dcXJwrPz/f7k0LaPfdd5/r9ddfd+3fv9+1b98+1/333+/q1auXq6SkxLvO7NmzXcnJya4NGza4du3a5br99ttdY8aMsXW7A9mOHTtcKSkprtTUVNe8efO8l7OfW8758+ddvXv3dj388MOu7du3u44dO+Zat26d6+jRo9510tPTXbGxsa7Vq1e7PvnkE9c3vvENV58+fVyXLl2yddsDzaJFi1ydO3d2vffee67jx4+73n77bVd0dLRryZIl3nXY19dmzZo1rv/4j/9w/fWvf9Vk51q1alWt3zdlv37961933XTTTa5t27a5Pv74Y1f//v1d06ZNc12voA0jt956q2vu3Lnen51Op6tnz56utLQ0W7errSkoKDAP+o0bN5qfL1686AoPDzcvMB6fffaZWWfr1q02bmlgKi4udg0YMMC1fv1619133+0NI+znljV//nzXnXfe2eDva2pqXN27d3ctXrzYe5neB5GRka4///nPFm1l2zBp0iTX97///VqXfetb33JNnz7dfM++bhl1w0hT9uvBgwfN3+3cudO7ztq1a10hISGuU6dOXdf2BOVpmsrKStm9e7cpQfl+GJ/+vHXrVlu3ra0pLCw0Xzt16mS+6n6vqqqqte8HDx4svXr1Yt9fAz0NM2nSpFr7U7GfW9a7774ro0aNkgcffNCcfhw+fLgsX77c+/vjx49LXl5erf2tHw6mp3/Z380zZswY2bBhgxw+fNj8/Mknn8jmzZtl4sSJ5mf2detoyn7Vr3pqRp8LHrq+Hj+3b99+XdcfEJ/a29LOnj1rzksmJCTUulx//vzzz23brrampqbG9DDccccdMmzYMHOZPtgjIiLMA7ruvtffoekyMjJkz549snPnzit+x35uWceOHZOlS5fKj3/8Y3n66afNPv/Xf/1Xs49nzpzp3af1vaawv5vnqaeeMh9fr+HZ4XCY1+pFixaZPgXFvm4dTdmv+lXDuK+wsDDzZvN6931QhhFY9659//795l0NWlZOTo7MmzdP1q9fbxqw0frBWt8Nvvjii+ZnrYzoY/uVV14xYQQt5y9/+Yu89dZbsnLlSrnhhhtk37595k2NNl2yr9uuoDxN06VLF5O4644s0J+7d+9u23a1JT/84Q/lvffek48++kiSkpK8l+v+1dNkFy9erLU++7559DRMQUGBjBgxwrwz0WXjxo3y29/+1nyv72bYzy1HRxcMHTq01mVDhgyR7Oxs871nn/Kacv1+8pOfmOrId7/7XTNi6aGHHpInnnjCjNRT7OvW0ZT9ql/1dcdXdXW1GWFzvfs+KMOIllZHjhxpzkv6vvPRn0ePHm3rtgU67YvSILJq1Sr58MMPzfA8X7rfw8PDa+17HfqrL+rs+6YbN26cZGVlmXeNnkXfuWsp2/M9+7nl6KnGukPUtaehd+/e5nt9nOuLse/+1lMNeh6d/d08ZWVlpgfBl7551Ndoxb5uHU3Zr/pV3+DomyEPfZ3X+0Z7S66LK4iH9mqX8BtvvGE6hB999FEztDcvL8/uTQtoc+bMMUPDMjMzXbm5ud6lrKys1pBTHe774YcfmiGno0ePNguuj+9oGsV+btnh02FhYWbY6ZEjR1xvvfWWq3379q4333yz1rBIfQ3529/+5vr0009dU6ZMYbjpNZg5c6YrMTHRO7RXh6F26dLF9e///u/eddjX1z76bu/evWbRw/9LL71kvv/yyy+bvF91aO/w4cPNEPfNmzeb0XwM7b1O//mf/2lerHW+ER3qq+OmcX30AV7fonOPeOgD+7HHHnPFx8ebF/RvfvObJrCgZcMI+7ll/f3vf3cNGzbMvIkZPHiw69VXX631ex0a+eyzz7oSEhLMOuPGjXMdOnTItu0NVEVFReZxrK/NUVFRrr59+5q5MSoqKrzrsK+vzUcffVTv67MGwKbu13PnzpnwoXO/xMTEuB555BETcq5XiP7v+morAAAA1y4oe0YAAID/IIwAAABbEUYAAICtCCMAAMBWhBEAAGArwggAALAVYQQAANiKMAIAAGxFGAEAALYijAAAAFsRRgAAgNjp/wPcrUn1XwforQAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(torch.tensor(lossi).view(-1, 1000).mean(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RNN_Model(\n",
              "  (embedding): Embedding(27, 32)\n",
              "  (gru): GRU(32, 150, batch_first=True)\n",
              "  (linear): Linear(in_features=150, out_features=27, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 237,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "metadata": {},
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def split_loss(split):\n",
        "    x,y = {\n",
        "        'train' : (Xtr, Ytr),\n",
        "        'val' : (Xdev, Ydev),\n",
        "        'test': (Xte, Yte),\n",
        "    }[split]\n",
        "    \n",
        "    x = model(x)\n",
        "    probs = x.view(x.shape[0], -1)\n",
        "    loss = F.cross_entropy(probs, y)\n",
        "    print(split, loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train 2.7619075775146484\n",
            "val 2.7619075775146484\n"
          ]
        }
      ],
      "source": [
        "split_loss('train')\n",
        "split_loss('val')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "index out of range in self",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[255]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m     10\u001b[39m     x = torch.tensor([context])\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     logits = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m     logits = logits.view(logits.shape[\u001b[32m0\u001b[39m], -\u001b[32m1\u001b[39m)\n\u001b[32m     13\u001b[39m     probs = F.softmax(logits, dim=\u001b[32m1\u001b[39m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[229]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mRNN_Model.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m      9\u001b[39m     \u001b[38;5;66;03m# x: (batch, seq)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m                  \u001b[38;5;66;03m# (batch, seq, n_emb)\u001b[39;00m\n\u001b[32m     11\u001b[39m     output, h_n = \u001b[38;5;28mself\u001b[39m.gru(x)              \u001b[38;5;66;03m# output: (batch, seq, n_hidden)\u001b[39;00m\n\u001b[32m     12\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.linear(output)                \u001b[38;5;66;03m# (batch, seq, vocab_size)\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/dev/ai-env/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/dev/ai-env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/dev/ai-env/lib/python3.13/site-packages/torch/nn/modules/sparse.py:190\u001b[39m, in \u001b[36mEmbedding.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/dev/ai-env/lib/python3.13/site-packages/torch/nn/functional.py:2551\u001b[39m, in \u001b[36membedding\u001b[39m\u001b[34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[39m\n\u001b[32m   2545\u001b[39m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[32m   2546\u001b[39m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[32m   2547\u001b[39m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[32m   2548\u001b[39m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[32m   2549\u001b[39m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[32m   2550\u001b[39m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[32m-> \u001b[39m\u001b[32m2551\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mIndexError\u001b[39m: index out of range in self"
          ]
        }
      ],
      "source": [
        "with open(\"generated_names.txt\", 'a') as f:\n",
        "    names = []\n",
        "    for _ in range(500):\n",
        "\n",
        "        context = [0] * block_size  # or whatever index corresponds to '.'\n",
        "        out = []\n",
        "        while True:\n",
        "            x = torch.tensor([context])\n",
        "            logits = model(x)\n",
        "            logits = logits[:, -1, :]  # Take the last timestep\n",
        "            probs = F.softmax(logits, dim=1)\n",
        "            ix = torch.multinomial(probs, num_samples=1).item()\n",
        "            context = context[1:] + [ix]\n",
        "            out.append(ix)\n",
        "            if ix == 0:  # assuming '.' index is 0\n",
        "                break\n",
        "\n",
        "    names.sort()\n",
        "    f.write('\\n'.join(names))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"generated_names.txt\", 'r') as f:\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "        name = name.split('\\n')[0]\n",
        "        if name in words:\n",
        "            print(f\"{name} exists\")\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOg9/fDb0gMi5cqgVYsQEep",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ai-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
